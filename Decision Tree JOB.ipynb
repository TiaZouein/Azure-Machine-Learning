{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1694352557761
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Entraînement et Optimisation des Hyperparamètres d'un Modèle de Machine Learning dans le Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons vous montrer comment entraîner un modèle d'apprentissage automatique sur le cloud et optimiser les hyperparamètres. Cette approche vous permettra d'éviter les plantages du kernel et les longs temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### **Workspace**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, vous devrez vous connecter à votre espace de travail Azure ML. L'espace de travail est la ressource de niveau supérieur pour Azure Machine Learning, fournissant un emplacement centralisé pour travailler avec tous les éléments que vous créez lorsque vous utilisez Azure Machine Learning.\n",
    "\n",
    "Nous utilisons DefaultAzureCredential pour accéder à l'espace de travail. DefaultAzureCredential devrait être capable de gérer la plupart des scénarios d'authentification du kit SDK Azure.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, saisissez votre ID d'abonnement, le nom du groupe de ressources et le nom de l'espace de travail. Pour trouver l'ID d'abonnement et le nom du groupe de ressources :\n",
    "\n",
    "- Dans la barre d'outils de Azure Machine Learning Studio en haut à droite, sélectionnez le nom de votre espace de travail.\n",
    "- Copiez la valeur du groupe de ressources et de l'ID d'abonnement dans le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1694352560603
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = \"votre subscription_id\"\n",
    "resource_group = \"votre resource_group\"\n",
    "workspace_name = \"nom\"\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### **Creating my Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour exécuter une tâche AzureML, vous aurez besoin d'un environnement. Un environnement est le runtime logiciel et les bibliothèques que vous souhaitez installer sur la machine de calcul sur laquelle vous effectuerez la formation. Il est similaire à votre environnement Python sur votre machine locale.\n",
    "\n",
    "AzureML propose de nombreux environnements préconfigurés ou prêts à l'emploi qui sont utiles pour des scénarios de formation et d'inférence courants. Vous pouvez également créer vos propres environnements \"personnalisés\" en utilisant une image Docker ou une configuration conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1694352565266
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name sklearn_envs is registered to workspace, the environment version is 91\n"
     ]
    }
   ],
   "source": [
    "custom_env_name = \"sklearn_envs\"\n",
    "job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    #chemin vers le fichier .yaml dans votre répertoire\n",
    "    description=\"Custom environment for sklearn - classification\",\n",
    "    conda_file=\"././dependencies.yaml\",\n",
    "    image=\"choose the image:latest\",\n",
    ")\n",
    "job_env = ml_client.environments.create_or_update(job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {job_env.name} is registered to workspace, the environment version is {job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AzureML a besoin d'une ressource de calcul pour exécuter une tâche. Il peut s'agir de machines mono-noeud ou multi-noeuds (cluster) avec un système d'exploitation Linux ou Windows, ou d'une infrastructure de calcul spécifique comme Spark.\n",
    "\n",
    "Pour cet exemple, nous avons besoin d'un cluster basique. Optons pour un modèle Standard_DS3_v2 avec 2 cœurs vCPU, 7 Go de RAM et créons une ressource de calcul Azure ML.\n",
    "\n",
    "Si le cluster ou la machine virtuelle est déjà présente, il suffit de spécifier son nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster = AmlCompute(\n",
    "        name='instance',\n",
    "        type=\"amlcompute\",\n",
    "        # Virtual Machine family\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=4,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "    )\n",
    "\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()\n",
    "\n",
    "print(\n",
    "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### **Launching the job to train the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez tous les éléments nécessaires pour exécuter votre tâche, il est temps de créer la tâche elle-même à l'aide du kit SDK Python Azure ML v2. Nous allons créer une tâche de type \"commande\".\n",
    "\n",
    "Une tâche de type \"commande\" AzureML est une ressource qui spécifie tous les détails nécessaires pour exécuter votre code de formation dans le cloud : les entrées et les sorties, le type de matériel à utiliser, les logiciels à installer et la manière d'exécuter votre code. La tâche de type \"commande\" contient les informations pour exécuter une seule commande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le job exécutera le script de formation \"Decision Tree.py\" en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1694353310400
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'sklearn_envs' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'sklearn_envs' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.18 MBs): 100%|██████████| 180203/180203 [00:00<00:00, 363538.41it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: dreamy_wire_9qv3m082cm\n",
      "Web View: https://ml.azure.com/runs/dreamy_wire_9qv3m082cm?wsid=/subscriptions/82ad5388-182f-442b-95e2-3378756be384/resourcegroups/rg-e7-e2-sbx-app-dlf-bas-01/workspaces/aml-e7-e2-fr-sbx-dlf-bas-001\n"
     ]
    }
   ],
   "source": [
    "python_job = command(\n",
    "    code=\"./src\", #chemin vers le script\n",
    "    display_name=\"name of the experiment\",\n",
    "    environment= job_env,\n",
    "    compute= \"instance\",\n",
    "    \n",
    "    inputs={\n",
    "        \"input_data\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"path of the input data\",\n",
    "        ),\n",
    "        \"criterion\" : \"entropy\",\n",
    "        \"max_depth\" : 50,\n",
    "        \"min_samples_leaf\" :20,\n",
    "        \"min_samples_split\" : 1000,\n",
    "        \"min_impurity_decrease\" : 0.0001,    \n",
    "        \"random_state\" : 42,\n",
    "        #\"ccp_alpha\" : 0.2,\n",
    "        },\n",
    "\n",
    "    outputs={\n",
    "        \"model_output\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"path to save the model\",\n",
    "        ),\n",
    "    },\n",
    "    command=\"python Decision Tree.py \\\n",
    "    --input_data ${{inputs.input_data}} \\\n",
    "    --criterion ${{inputs.criterion}} --max_depth ${{inputs.max_depth}}\\\n",
    "    --min_samples_leaf ${{inputs.min_samples_leaf}} --min_samples_split ${{inputs.min_samples_split}}\\\n",
    "    --min_impurity_decrease ${{inputs.min_impurity_decrease}} --random_state ${{inputs.random_state}}\\\n",
    "     --model_output ${{outputs.model_output}}\"\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(python_job)\n",
    "\n",
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### **Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le \"sweep job\" est un processus essentiel dans le domaine de l'apprentissage automatique visant à trouver les paramètres optimaux pour un modèle. Les hyperparamètres, qui sont des réglages qui ne sont pas appris par le modèle lui-même, jouent un rôle crucial dans la performance d'un algorithme d'apprentissage automatique.\n",
    "\n",
    "Une tâche de recherche d'hyperparamètres consiste à parcourir différentes combinaisons d'hyperparamètres pour déterminer celles qui produisent les meilleurs résultats en termes de précision, de généralisation et d'autres mesures de performance. Cette approche permet d'optimiser la configuration du modèle sans avoir à effectuer manuellement une multitude d'expérimentations fastidieuses.\n",
    "\n",
    "L'optimisation des hyperparamètres dans le cloud présente des avantages considérables. L'utilisant des ressources infiniment évolutives du cloud peut accélérer les expérimentations, explorer des espaces de recherche plus vastes, réaliser des économies de coûts, et assurer la sécurité et la sauvegarde des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1692359480585
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "job_for_sweep = python_job(\n",
    "    max_depth=Choice(values=[50, 150, 500, 1000]),\n",
    "    min_samples_split=Choice(values=[10, 50, 100, 300, 500,1000]),\n",
    "    min_impurity_decrease=Choice(values=[0.0001, 0.001, 0.01, 0.1]),\n",
    "    min_samples_leaf=Choice(values=[20, 50, 100, 300, 500, 800]),\n",
    "    criterion=Choice(values=['gini', 'entropy']),\n",
    "    ccp_alpha=Choice(values=[0.0, 0.001, 0.01, 0.1, 0.3, 0.6]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1692359769259
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: nifty_quince_zzvk0qrqj0\n",
      "Web View: https://ml.azure.com/runs/nifty_quince_zzvk0qrqj0?wsid=/subscriptions/82ad5388-182f-442b-95e2-3378756be384/resourcegroups/rg-e7-e2-sbx-app-dlf-bas-01/workspaces/aml-e7-e2-fr-sbx-dlf-bas-001\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2023-08-18T11:56:20.592647][GENERATOR][INFO]Trying to sample '1000' jobs from the hyperparameter space\n",
      "[2023-08-18T11:56:27.8656175Z][SCHEDULER][INFO]Scheduling job, id='nifty_quince_zzvk0qrqj0_1' \n",
      "[2023-08-18T11:56:27.8645210Z][SCHEDULER][INFO]Scheduling job, id='nifty_quince_zzvk0qrqj0_0' \n",
      "[2023-08-18T11:58:34.9997613Z][SCHEDULER][INFO]Successfully scheduled a job. Id='nifty_quince_zzvk0qrqj0_998' \n",
      "[2023-08-18T11:58:34.863449][GENERATOR][INFO]Successfully sampled '1000' jobs, they will soon be submitted to the execution target.\n",
      "[2023-08-18T11:58:35.1810807Z][SCHEDULER][INFO]Successfully scheduled a job. Id='nifty_quince_zzvk0qrqj0_999' \n"
     ]
    }
   ],
   "source": [
    "sweep_job = job_for_sweep.sweep(\n",
    "    sampling_algorithm=\"grid\", # we can use \"random\"\n",
    "    primary_metric=\"f1_score\",\n",
    "    goal=\"Maximize\",\n",
    "    #max_total_trials=200,\n",
    "    #max_concurrent_trials=500, \n",
    ")\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "ml_client.jobs.stream(returned_sweep_job.name)\n",
    "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1691260738329
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jovial_hominy_r8my72krcx_90'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1691260738538
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.822784810126583'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_sweep_job.properties[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1691260739146
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_sweep_job.properties[\"best_metric_status\"]"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
